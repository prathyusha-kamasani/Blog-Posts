{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac6e2a5b-996a-4a1a-b16f-357b95078ab1",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68dfea9c-f216-44ee-83b8-ad1dcb675765",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "%pip install semantic-link-labs\n",
    "import sempy_labs as labs\n",
    "from sempy_labs.tom import connect_semantic_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc46fe86-4574-40f1-8bea-ad14406498d6",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "dataset = 'Dataset Name'\n",
    "workspace = 'Workspace ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecd1460-5b3e-437c-afbb-a4c4914ac07a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "with connect_semantic_model(dataset=dataset, readonly=True, workspace=workspace) as tom:\n",
    "    for t in tom.model.Tables:\n",
    "        print(t.Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0e38b6-e255-436c-bb97-644a98f6b571",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Rename objects in the semantic model\n",
    "with connect_semantic_model(dataset=dataset, readonly=False, workspace=workspace) as tom:\n",
    "    for t in tom.model.Tables:\n",
    "        t.Name = t.Name.replace('_',' ')\n",
    "\n",
    "with connect_semantic_model(dataset=dataset, readonly=False, workspace=workspace) as tom:\n",
    "    for c in tom.all_columns():\n",
    "        c.Name = c.Name.replace('_',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8c7d66-5600-47e8-80c6-c829255c4840",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# Function to convert to Snake case\n",
    "def to_title_case(snake_str):\n",
    "    return snake_str.title()\n",
    "# Convert table names to title case\n",
    "with connect_semantic_model(dataset=dataset, readonly=False, workspace=workspace) as tom:\n",
    "    for t in tom.model.Tables:\n",
    "        t.Name = to_title_case(t.Name)\n",
    "\n",
    "# Convert column names to Snake case\n",
    "with connect_semantic_model(dataset=dataset, readonly=False, workspace=workspace) as tom:\n",
    "    for c in tom.all_columns():\n",
    "        c.Name = to_title_case(c.Name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eef8484-487f-4830-a67a-7422a147272b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "synapse_pyspark"
    }
   },
   "outputs": [],
   "source": [
    "# with connect_semantic_model(dataset=dataset, readonly=True, workspace=workspace) as tom:\n",
    "#     for t in tom.model.Tables:\n",
    "#         print(t.Name)"
   ]
  }
 ],
 "metadata": {
  "dependencies": {
   "environment": {
    "environmentId": "01bf77ce-89cf-4ccb-8ec2-e4c56617759d",
    "workspaceId": "b13519ad-75cb-40af-a287-ac043f3d3f2a"
   }
  },
  "kernel_info": {
   "name": "synapse_pyspark"
  },
  "kernelspec": {
   "display_name": "Synapse PySpark",
   "language": "Python",
   "name": "synapse_pyspark"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "synapse_pyspark",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
